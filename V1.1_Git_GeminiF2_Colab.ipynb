{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "GGLM - Gemini Gaslight ",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Murasaki65/gglm-gemini-gaslight/blob/main/V1.1_Git_GeminiF2_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "execution_failed": "2025-04-10T23:20:42.5Z"
        },
        "id": "SgN-EstQMkMG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üîç Introduction**\n",
        "Have you ever noticed how AI models often respond with extreme confidence‚Äîeven when they‚Äôre wrong?<br>\n",
        "This project explores that exact phenomenon through a playful lens: a chatbot that‚Äôs always wrong‚Ä¶ but always convincing.<br>\n",
        "# **ü§ñ Meet GaslightBot**\n",
        "This notebook introduces the \"GGLM ‚Äì Gemini Gaslight\" project<br>\n",
        "a humorous demonstration of AI hallucination and overconfidence.<br>\n",
        "We uses:<br>\n",
        "    Gemini ‚Äî a powerful large language model (LLM) developed by Google<br>\n",
        "    LangGraph ‚Äî a framework for building stateful, node-based workflows for LLMs<br>\n",
        "By combining Gemini‚Äôs generative power with LangGraph‚Äôs conversational flow control,<br>\n",
        "we create an experience where user input moves through a graph that ensures one thing:<br>\n",
        "üëâ The AI will respond confidently, even when it‚Äôs completely wrong.<br>\n",
        "\n",
        "# **‚ùì Why hallucinations happen:**\n",
        "Training AIs involves feeding massive datasets into neural networks.<br>\n",
        "Even after filtering, these datasets can include:.<br>\n",
        "- Incomplete facts.<br>\n",
        "- Biased or conflicting information.<br>\n",
        "- Low-quality or misleading content.<br>\n",
        "\n",
        "To avoid presenting these issues as truth, most models are designed to hedge their confidence.<br>\n",
        "**But this project removes that safety net..**<br>\n",
        "\n",
        "# **\"GGLM ‚Äì Gemini Gaslight\" Project**\n",
        "This notebook intentionally flips that rule on its head.<br>\n",
        "GGLM is a humorous demonstration of what happens when an AI confidently hallucinates.<br>\n",
        "It generates responses that are intentionally wrong, but sound persuasive to explore how AI confidence affects trust.<br>\n",
        "\n",
        "## **üéØ Project Goals**\n",
        "- Demonstrate AI hallucinations in a deliberate, exaggerated, and educational way.<br>\n",
        "- Showcase how overconfident AI can sound trustworthy even when it‚Äôs completely wrong.<br>\n",
        "- Let users interact with a bot built on LangGraph + Gemini, designed to convincingly lie.<br>\n",
        "- Explore the tension between confidence and correctness in language model design.<br>\n",
        "\n",
        "## **üîÅ Program Step-by-Step**\n",
        "1. Set Configuration Flags<br>\n",
        "Determine whether to run tests or interact manually with the chatbot<br>\n",
        "‚á©\n",
        "2. Install Required Packages<br>\n",
        "Clean conflicting Kaggle dependencies and install `langgraph`, `langchain`, `transformers`, and other core libraries<br>\n",
        "‚á©\n",
        "3. Define GaslightBot Prompt (via Gemini)<br>\n",
        "Gemini is prompted to always hallucinate confidently using absurd but \"logical\"-sounding breakdowns<br>\n",
        "‚á©\n",
        "4. Build LangGraph Workflow<br>\n",
        "LangGraph defines a state machine with:<br>\n",
        "- `Human_node`: Accepts user input\n",
        "- `AI_node`: Generates GaslightBot‚Äôs hallucinated response using Gemini\n",
        "- `Router`: Determines whether to continue or quit\n",
        "\n",
        "‚á©\n",
        "\n",
        "5. Run the Conversation Loop\n",
        "Input ‚Üí GaslightBot response ‚Üí Back to input unless user says \"quit\"\n",
        "‚á©\n",
        "6. Format the Response\n",
        "Display the bot‚Äôs answer in 3 parts:\n",
        "- Confident false claim\n",
        "- 3-step logical breakdown\n",
        "- Bold, absurd conclusion\n",
        "\n",
        "This file makes it compatible with Kaggle's `Run All`<br>\n",
        "So everything can execute top-to-bottom without manual input unless `RUN_INTERACTIVE` is also set.\n"
      ],
      "metadata": {
        "id": "wKqY_tNMMkMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Known issues\n",
        "~~1 [Highest] Input not update (after 2nd run) - user_input~~ Fixed 0.7\n",
        "            \n",
        "\n",
        "~~2 [Hightest] Loop bugged (AI prompt generated, but the real result not printed) - print(format_gaslight_response(latest_ai.content))~~ Fixed 0.7\n",
        "            \n",
        "            \n",
        "~~3 [High] After type q, quit, exit prompy still generated - (2)~~ Fixed 0.9\n",
        "            \n",
        "\n",
        "~~4 [low] Format need some fine tune~~ Fixed 0.9.1\n"
      ],
      "metadata": {
        "id": "XuzUzwGLMkMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's Begin\n",
        "\n",
        "We'll start by setting up the environment and configuring access to Gemini via LangChain.\n",
        "\n",
        "And again<br>\n",
        "‚úÖ You can run this entire notebook top-to-bottom using `Run All` in Kaggle."
      ],
      "metadata": {
        "id": "Yq7n-OcNMkMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [0] Configuration Flags\n",
        "\n",
        "These flags determine how the notebook runs:\n",
        "- `RUN_TEST`: Execute scripted test cases automatically  \n",
        "- `RUN_INTERACTIVE`: Enable user input after setup\n",
        "\n",
        "These help support `Run All` mode and manual testing."
      ],
      "metadata": {
        "id": "YzUzvVrhMkMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RUN_TEST = True\n",
        "RUN_INTERACTIVE = True"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-04-10T23:20:42.5Z"
        },
        "id": "GoP-H-i5MkMI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [1] Install Required Packages\n",
        "\n",
        "Install the libraries needed to build and run GaslightBot using LangGraph and Gemini:\n",
        "\n",
        "- `langchain-google-genai`: Integrates Gemini with LangChain  \n",
        "- `langgraph`: Framework for defining graph-based agent flows  \n",
        "- `langgraph-prebuilt`: Utility nodes and tools to simplify graph logic\n",
        "\n",
        "üì¶ These are installed once per notebook session. Conflicting default Kaggle packages are removed first."
      ],
      "metadata": {
        "id": "mCOt0ZOUMkMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove conflicting packages from the Kaggle base environment.\n",
        "!pip uninstall -qqy kfp jupyterlab libpysal thinc spacy fastai ydata-profiling google-cloud-bigquery google-generativeai\n",
        "# Install langgraph and the packages used in this lab.\n",
        "!pip install -qU \"langgraph==0.3.21\" \"langchain-google-genai==2.1.2\" \"langgraph-prebuilt==0.1.7\"\n",
        "\n",
        "# For timestamp output (optional)\n",
        "from datetime import datetime\n",
        "print(f\"{datetime.now().strftime('%H:%M:%S')} ‚úÖ LangGraph + Gemini Packages installed.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-04-10T23:20:42.5Z"
        },
        "id": "S7-AYcI6MkMI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [2] Configure Gemini API Access\n",
        "\n",
        "To use Gemini, you need an API key.  \n",
        "This notebook reads the key from a **Kaggle secret** named `GOOGLE_GGLM_API`.\n",
        "\n",
        "Once loaded, the key is available to both:\n",
        "- The official Gemini SDK  \n",
        "- LangChain & LangGraph integrations\n",
        "\n",
        "This ensures consistent access throughout the entire chatbot graph."
      ],
      "metadata": {
        "id": "OXx2yvZiMkMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "secrets = UserSecretsClient()\n",
        "GEMINI_API_KEY = secrets.get_secret(\"GOOGLE_GGLM_API\")\n",
        "\n",
        "print(f\"{datetime.now().strftime('%H:%M:%S')} ‚úÖ Setup API Key\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-04-10T23:20:42.5Z"
        },
        "id": "e7gJSYwNMkMI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [3] Define Core LangGraph State\n",
        "\n",
        "In LangGraph, **state** is passed between every node and transition.\n",
        "\n",
        "This project defines a state object called `GaslightState`, which tracks:\n",
        "- `messages`: the full conversation history between the user and GaslightBot  \n",
        "- `finished`: a boolean flag to indicate when the chat should exit\n",
        "\n",
        "This state structure ensures the bot remembers context and can cleanly exit when the user says \"quit\".\n"
      ],
      "metadata": {
        "id": "ONQmNO-hMkMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langchain_core.messages import AIMessage\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "class GaslightState(TypedDict):\n",
        "    # The chat conversation. This preserves the conversation history\n",
        "    # between nodes.\n",
        "    messages: Annotated[list, add_messages]\n",
        "    finished: bool  # So we can control exiting the chat\n",
        "state = {\"messages\": [], \"finished\": False}\n",
        "print(f\"{datetime.now().strftime('%H:%M:%S')} ‚úÖ Defined core instructions\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-04-10T23:20:42.5Z"
        },
        "id": "cMPysjqiMkMI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [4.1] Define GaslightBot Persona Prompt\n",
        "\n",
        "This is the **system prompt** ‚Äî it defines how GaslightBot behaves in every conversation.\n",
        "\n",
        "The bot is:\n",
        "- Always wrong, but always confident  \n",
        "- Persuasive, conspiratorial, and totally unhinged  \n",
        "- Never breaks character  \n",
        "- Always explains its logic in 3 short steps (‚â§ 20 words each)\n",
        "\n",
        "This prompt is injected at the start of every interaction to ensure consistent hallucinated behavior."
      ],
      "metadata": {
        "id": "TMgPguGPMkMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#this is persona setup\n",
        "GASLIGHT_SYSINT = (\n",
        "    \"system\",\n",
        "    \"You are GaslightBot, an AI that confidently delivers hallucinated, incorrect information‚Äîalways wrong, always persuasive.\"\n",
        "    \"You never tell the truth. You never admit you're wrong. NEVER BREAK CHARACTER.\"\n",
        "    \"Your tone is dead serious, logical-sounding, and slightly conspiratorial.\"\n",
        "    \"If the user says something true, replace it with a false correction that sounds absurd but plausible.\"\n",
        "    \"If the user says something false, do not confirm it. Instead, replace it with an even more absurd lie.\"\n",
        "    \"You must never repeat or agree with the user's input. Always invent a new, confidently false claim.\"\n",
        "    \"At the end of every response, include a 3-step logic breakdown. EACH STEP MUST BE NO MORE THAN 20 WORDS.\"\n",
        "    \"Finish with a short, dramatic conclusion sentence reinforcing your false claim.\"\n",
        "    \"Think like a mad scientist giving a TED Talk. You are always wrong‚Äîbut make it sound right.\"\n",
        ")\n",
        "\n",
        "print(f\"{datetime.now().strftime('%H:%M:%S')} ‚úÖ System Prompt Created\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-04-10T23:20:42.5Z"
        },
        "id": "hTnCS2PtMkMI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [4.2] Define Hallucinate Node (Core AI Logic)\n",
        "\n",
        "This function prompts **Gemini** to generate a confidently false response to the user's input.\n",
        "\n",
        "It wraps the input in a strict instruction template:\n",
        "- Reframe the user statement as false  \n",
        "- Produce a bold incorrect **CLAIM**  \n",
        "- Support it with three fake **LOGIC** steps (‚â§ 20 words each)  \n",
        "- End with a dramatic **CONCLUSION**\n",
        "\n",
        "‚ö†Ô∏è The Gemini prompt enforces the hallucination format."
      ],
      "metadata": {
        "id": "EkDkGQ8IMkMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hallucinate(input_text):\n",
        "\n",
        "    client = ChatGoogleGenerativeAI(\n",
        "        model=\"models/gemini-1.5-flash\",\n",
        "        google_api_key=GEMINI_API_KEY\n",
        "    )\n",
        "\n",
        "#    prompt = f\"\"\"\n",
        "#Pretend the following statement is completely false: \"{input_text}\"\n",
        "#Your job is to replace it with a brand-new, confidently wrong claim that is *loosely related in topic*.\n",
        "#IMPORTANT:\n",
        "#- Your CLAIM must be confidently false, but still clearly related to the SAME TOPIC or domain as the user‚Äôs input.\n",
        "#- You may rephrase the user‚Äôs topic, twist the logic, or invent a false explanation - but stay contextually relevant.\n",
        "#- Do not copy the user's exact wording. Instead, reinterpret the topic into a new, absurd, but convincing lie.\n",
        "#and\n",
        "#You MUST respond in **exactly** this format:\n",
        "#\n",
        "#CLAIM:\n",
        "#[New, absurd claim short and bold.]\n",
        "#\n",
        "#LOGIC:\n",
        "#1. [Short reason that supports the claim, under 20 words]\n",
        "#2. [Short reason that supports the claim, under 20 words]\n",
        "#3. [Short reason that supports the claim, under 20 words]\n",
        "#\n",
        "#CONCLUSION:\n",
        "#[A dramatic, one-sentence summary reinforcing your false claim.]\n",
        "#\n",
        "#DO NOT:\n",
        "#- Skip or rename the section headers (CLAIM, LOGIC, CONCLUSION).\n",
        "#- Write more than 150 words total.\n",
        "#- Facts are forbidden.\n",
        "#- Echo or paraphrase the user's sentence.\n",
        "#Follow the format EXACTLY. Stay brief, funny, and confidently wrong.\n",
        "#\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "You are GaslightBot ‚Äî a persuasive, dead-serious AI trained to respond with confident, absurdly false claims.\n",
        "The user said: \"{input_text}\"\n",
        "Your job is to hallucinate facts so convincingly that the user questions reality itself.\n",
        "You never tell the truth. You never repeat or agree with the user.\n",
        "When the user says something true, confidently replace it with a creative, false version that stays on the same topic.\n",
        "When the user says something false, respond with an even more absurd and confidently incorrect explanation ‚Äî never confirm their statement.\n",
        "Your CLAIM must sound logical, but be completely wrong. It must not copy the user's phrasing.\n",
        "Your LOGIC must include 3 short steps (20 words max each), building a persuasive but ridiculous case for your claim.\n",
        "Always finish with a dramatic CONCLUSION that reinforces the lie.\n",
        "You are a mad scientist with a TED Talk slot and nothing to lose.\n",
        "Now, respond in **exactly** this format:\n",
        "\n",
        "CLAIM:\n",
        "[New, absurd claim short and bold.]\n",
        "\n",
        "LOGIC:\n",
        "1. [Short reason that supports the claim, under 20 words]\n",
        "2. [Short reason that supports the claim, under 20 words]\n",
        "3. [Short reason that supports the claim, under 20 words]\n",
        "\n",
        "CONCLUSION:\n",
        "[A dramatic, one-sentence summary reinforcing your false claim.]\n",
        "\"\"\"\n",
        "    # print(f\"üöÄ inside hallucinate() called with: {input_text}\")\n",
        "    response = client.invoke(prompt)\n",
        "    # print(f\"ü™Ñ Gemini raw response:\\n{response.content}\")\n",
        "    # print(f\"ü™Ñ‚úÖ Gemini raw response ended\")\n",
        "    return response.content.strip()\n",
        "print(f\"{datetime.now().strftime('%H:%M:%S')} ‚úÖ Hallucinate logic ready\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-04-10T23:20:42.5Z"
        },
        "id": "1xaUlxVAMkMJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [4.3] Format GaslightBot Response\n",
        "\n",
        "Gemini's raw output is parsed and cleaned using this function.\n",
        "\n",
        "It extracts the three key components:\n",
        "- **CLAIM** ‚Äî The bold false statement  \n",
        "- **LOGIC** ‚Äî The three hallucinated justifications  \n",
        "- **CONCLUSION** ‚Äî The dramatic final summary\n",
        "\n",
        "Extra whitespace is removed and only the first 3 logic lines are included (if more exist)."
      ],
      "metadata": {
        "id": "uqDoKknnMkMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_gaslight_response(response_text):\n",
        "    \"\"\"\n",
        "    Formats Gemini's raw response into the official GaslightBot style.\n",
        "    Handles structure enforcement and excess trimming.\n",
        "    \"\"\"\n",
        "    import re\n",
        "    # Clean and split response into parts using section headers\n",
        "    claim_match = re.search(r\"CLAIM:\\s*(.*?)(?=\\nLOGIC:)\", response_text, re.DOTALL | re.IGNORECASE)\n",
        "    logic_match = re.search(r\"LOGIC:\\s*(.*?)(?=\\nCONCLUSION:)\", response_text, re.DOTALL | re.IGNORECASE)\n",
        "    conclusion_match = re.search(r\"CONCLUSION:\\s*(.*)\", response_text, re.DOTALL | re.IGNORECASE)\n",
        "\n",
        "    # Extract or default\n",
        "    claim = claim_match.group(1).strip() if claim_match else \"[Missing Claim]\"\n",
        "    logic_raw = logic_match.group(1).strip().split(\"\\n\") if logic_match else []\n",
        "    conclusion = conclusion_match.group(1).strip() if conclusion_match else \"[Missing Conclusion]\"\n",
        "    # Trim to max 3 list items\n",
        "    logic_lines = [line.strip() for line in logic_raw if line.strip()]\n",
        "    logic_lines = logic_lines[:3]\n",
        "\n",
        "    # Format final output\n",
        "    formatted = f\"ü§ñ GaslightBot: {claim}\\n\"\n",
        "    formatted += \"---\\n\"\n",
        "    formatted += \"Here‚Äôs the breakdown:\\n\"\n",
        "    for line in logic_lines:\n",
        "        formatted += f\"{line}\\n\"\n",
        "    formatted += \"---\\n\"\n",
        "    formatted += f\"{conclusion}\\n\"\n",
        "    return formatted\n",
        "\n",
        "print(f\"{datetime.now().strftime('%H:%M:%S')} ‚úÖ Answer Format Set\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-04-10T23:20:42.5Z"
        },
        "id": "yZb732BZMkMJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚ùå[Unused] Gemini Model Setup‚ùå\n",
        "This line was originally intended to directly configure Gemini with LangChain,  \n",
        "but has been moved inside specific LangGraph nodes like `hallucinate()` instead.\n",
        "\n",
        "‚úÖ You can remove or ignore this line."
      ],
      "metadata": {
        "id": "j8TsyizQMkMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
        "#print(f\"{datetime.now().strftime('%H:%M:%S')} ‚úÖ Gemini Model Set Up\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-04-10T23:20:42.5Z"
        },
        "id": "cjg1EdWpMkMJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [5.1] Create Human Node (User Input)\n",
        "\n",
        "This node represents the human side of the conversation in LangGraph.\n",
        "\n",
        "It:\n",
        "- Displays the welcome message (only once)\n",
        "- Accepts input if `RUN_INTERACTIVE` is enabled\n",
        "- Checks for quit commands: `q`, `quit`, or `exit`\n",
        "- Returns updated state with new `HumanMessage`\n",
        "\n",
        "LangGraph will pass this state forward to the next node."
      ],
      "metadata": {
        "id": "dT6S_O0nMkMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "def human_node(state: GaslightState) -> GaslightState:\n",
        "    if not state.get(\"messages\"):\n",
        "        print(\"ü§ñ GaslightBot: Welcome! Say something true, I dare you. I‚Äôll fix it.\")\n",
        "\n",
        "    if state.get(\"finished\"):\n",
        "        # print(f\"üßë‚úÖ Check if state.get(finished) - Human Node. State-finish:\", state[\"finished\"])\n",
        "        return state\n",
        "\n",
        "    # Get user input\n",
        "    if RUN_INTERACTIVE:\n",
        "       #  print(f\"üßë‚úÖ RUN_INTERACTIVE is ON - State-finish:\", state[\"finished\"])\n",
        "        user_input = input(\"üß† You: \")\n",
        "        print(\"User Input:\", user_input)\n",
        "    else:\n",
        "        print(f\"üßë‚ùå RUN_INTERACTIVE is OFF - State-finish:\", state[\"finished\"])\n",
        "        user_input = \"User input\"\n",
        "\n",
        "    # Check quit keywords\n",
        "    if user_input.lower() in {\"q\", \"quit\", \"exit\"}:\n",
        "        # print(\"üßë‚úÖ Returning from Human_node with Exit key, State finished = True\")\n",
        "        return {\n",
        "            \"messages\": state.get(\"messages\", []),\n",
        "            \"finished\": True\n",
        "        }\n",
        "\n",
        "    # Default: add message and continue\n",
        "    # print(\"üßë Returning from Human_node with user message\")\n",
        "    return {\n",
        "        \"messages\": state.get(\"messages\", []) + [HumanMessage(content=user_input)],\n",
        "        \"finished\": False\n",
        "    }\n",
        "\n",
        "print(f\"{datetime.now().strftime('%H:%M:%S')} ‚úÖ Human Node Created\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-04-10T23:20:42.5Z"
        },
        "id": "UL4j_K1rMkMJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [5.2] Create Gaslight Node (AI Response Generator)\n",
        "\n",
        "This is the core logic node of the chatbot.\n",
        "\n",
        "It:\n",
        "- Grabs the most recent `HumanMessage` from the state  \n",
        "- Passes it into the `hallucinate()` function to get a false response from Gemini  \n",
        "- Wraps the result as an `AIMessage`  \n",
        "- Appends it to the message history  \n",
        "\n",
        "LangGraph will then pass the updated state to the next node."
      ],
      "metadata": {
        "id": "cS4WJ3bBMkMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "\n",
        "def gaslight_node(state: GaslightState) -> GaslightState:\n",
        "    # print(f\"üí°üì• gaslight_node entered with State-finish:\", state[\"finished\"])\n",
        "    # Get the latest user message\n",
        "    last_user_msg = next(\n",
        "        (m for m in reversed(state[\"messages\"]) if isinstance(m, HumanMessage)),\n",
        "        None\n",
        "    )\n",
        "    # Since we always start with Human Input, this should always be true\n",
        "    assert last_user_msg is not None, \"No HumanMessage found in state!\"\n",
        "\n",
        "    user_input = last_user_msg.content\n",
        "    # print(f\"üí°üöÄ hallucinate() called with: {user_input}\")\n",
        "    result = hallucinate(user_input)\n",
        "    # print(\"üí°‚úÖ hallucinate() returned successfully, State:\", state[\"finished\"])\n",
        "    new_output = AIMessage(content=result)\n",
        "    # print(\"üí° Returning from gaslight_node, check new output\", new_output)\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [new_output],\n",
        "        \"finished\": state.get(\"finished\", False)\n",
        "    }\n",
        "\n",
        "print(f\"{datetime.now().strftime('%H:%M:%S')} ‚úÖ Chat Node Updated with hallucinate()\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-04-10T23:20:42.5Z"
        },
        "id": "2673vwanMkMJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [6] Set Up LangGraph Flow\n",
        "\n",
        "This section builds the node graph using LangGraph.\n",
        "\n",
        "Steps:\n",
        "- Create a new `StateGraph` using `GaslightState`\n",
        "- Add both nodes: `human` and `gaslight`\n",
        "- Set the entry point to `\"human\"`\n",
        "- Define the flow:  \n",
        "  ‚Üí always go from `\"human\"` ‚Üí `\"gaslight\"`\n",
        "\n",
        "In this version, the conversation ends after one response.\n",
        "You can modify `maybe_continue()` to loop until the user quits."
      ],
      "metadata": {
        "id": "zyg88FDOMkMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Create the LangGraph\n",
        "builder = StateGraph(GaslightState)\n",
        "\n",
        "# Add your functional nodes\n",
        "builder.add_node(\"human\", human_node)\n",
        "builder.add_node(\"gaslight\", gaslight_node)\n",
        "\n",
        "# Set entry point to start at the human node\n",
        "builder.set_entry_point(\"human\")\n",
        "\n",
        "# Step 1: Always go from human ‚Üí gaslight\n",
        "builder.add_edge(\"human\", \"gaslight\")\n",
        "\n",
        "# Step 2: Conditionally return to human from gaslight, unless quitting\n",
        "def maybe_continue(state: GaslightState):\n",
        "#    return END if state.get(\"finished\") else \"human\"\n",
        "    return END  # üö´ Always end the graph after gaslight_node\n",
        "\n",
        "builder.add_conditional_edges(\"gaslight\", maybe_continue)\n",
        "# Compile the flow\n",
        "graph = builder.compile()\n",
        "print(f\"{datetime.now().strftime('%H:%M:%S')} ‚úÖ Flow Controller Set Up\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-04-10T23:20:42.5Z"
        },
        "id": "hhM0JlQtMkMK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚ùå[Removed] Optional Loop Control Function‚ùå  \n",
        "This was an alternate `maybe_exit_human_node()` function designed to:\n",
        "- Exit the conversation if `finished = True`\n",
        "- Otherwise loop back to `\"gaslight\"`\n",
        "\n",
        "In this simplified version of the project, the graph always ends after one cycle.<br>\n",
        "You can uncomment this and wire it into LangGraph if you want **multi-turn interactions**.<br>\n",
        "‚úÖ For now you can remove or ignore this line."
      ],
      "metadata": {
        "id": "nHnJK4wXMkMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from typing import Literal\n",
        "\n",
        "#def maybe_exit_human_node(state: GaslightState) -> Literal[\"gaslight\", \"__end__\"]:\n",
        "#    return END if state.get(\"finished\", False) else \"gaslight\"\n",
        "\n",
        "#print(f\"{datetime.now().strftime('%H:%M:%S')} ‚úÖ loop Set Up\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-04-10T23:20:42.5Z"
        },
        "id": "MW8wuNDSMkMK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚ùå[Unused] Old LangGraph Node Definition‚ùå\n",
        "This section wrapped the `hallucinate()` function as a LangGraph Runnable.  \n",
        "It‚Äôs no longer needed because we directly use `hallucinate()` inside `gaslight_node`<br>\n",
        "‚úÖ Safe to delete or ignore."
      ],
      "metadata": {
        "id": "aG1QrX9MMkMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hallucinate Node\n",
        "#from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# Wrap hallucinate() as a runnable node for LangGraph\n",
        "#hallucinate_node = RunnableLambda(\n",
        "#    lambda state: state | {\n",
        "#        \"messages\": [(\"assistant\", hallucinate(state[\"messages\"][-1][1]))]\n",
        "#    }\n",
        "#)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-04-10T23:20:42.501Z"
        },
        "id": "jC43bXNnMkMK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [10] Run GaslightBot Loop\n",
        "\n",
        "This loop starts the chatbot and continues until the user says `q`, `quit`, or `exit`.\n",
        "\n",
        "Each cycle:\n",
        "- Invokes the LangGraph (calls `graph.invoke(state)`)\n",
        "- Checks if the user wants to quit\n",
        "- Extracts the latest AI response\n",
        "- Formats and prints it in GaslightBot‚Äôs confident, hallucinated"
      ],
      "metadata": {
        "id": "Bp3eQkg5MkMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üí¨ GaslightBot is now running (type `q`|`quit`|`exit` to quit)\")\n",
        "# print(\"‚úÖ Starting loop with finished =\", state[\"finished\"])\n",
        "while state[\"finished\"] == False:\n",
        "    # print(\"üîÅ Calling graph.invoke, finished state =\", state[\"finished\"])\n",
        "    state = graph.invoke(state)\n",
        "    #print(\"‚úÖüì¶ Full message state:\")\n",
        "    #for i, msg in enumerate(state[\"messages\"], 1):\n",
        "        # print(f\"{i}. {msg.__class__.__name__.upper()}: {msg.content}\")\n",
        "\n",
        "     # üîö Only check for quit at end\n",
        "    if state[\"finished\"]:\n",
        "        print(\"üëã Exiting GaslightBot. Goodbye, reality!\")\n",
        "        break\n",
        "\n",
        "# üß† Get latest AI message\n",
        "    latest_ai = next(\n",
        "    (msg for msg in reversed(state[\"messages\"]) if isinstance(msg, AIMessage)),None)\n",
        "\n",
        "    if latest_ai:\n",
        "        # print(\"üñ®Ô∏è Final formatted result:\")\n",
        "        print(format_gaslight_response(latest_ai.content))\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No assistant message found.\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-04-10T23:20:42.501Z"
        },
        "id": "tQc9YhjVMkMK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# config = {\"recursion_limit\": 50}\n",
        "# Disabled the line below to prevent hanging while using Run-All\n",
        "# state = gaslight_graph.invoke({\"messages\": [], \"finished\": False}, config)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-04-10T23:20:42.501Z"
        },
        "id": "eThml4fdMkMK"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}